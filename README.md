# Forked edition!
Here is a summary of all the changes and why I made them:
- `darts/utils/data/inference_dataset.py` - Changed `future_end` variable to the last entry in the covariate series. This is so that we can infer using information from `future_covariate` time series that extend past the set  `output_chunk_length`. This lets us keep `output_chunk_length` to 1 (predict one time step at a time), while we are still able to take information from the future into account.
- `darts/models/forecasting/tcn_model.py` - Added a linear decoding layer at the end of the model. This is actually related to an issue I posted on the Github page of darts (https://github.com/unit8co/darts/issues/1965). The way the model works at the moment is that it produces an output that is a function of `input_chunk_length`, which doesn't really make sense. In my modification I changed it to be a function of `output_chunk_length` using a linear layer at the end (this is consistent with most parts of the reference implementation they were using at https://github.com/locuslab/TCN). I think there was just some discussion about making a nice superclass for providing a separate decoder, which at the time of implementing the model was probably not a priority.
- `darts/utils/data/training_dataset.py` - Changed the index at the end for covariates of type `CovariateType.FUTURE` to use `input_chunk_length` instead of `output_chunk_length`. This is similar to the first change I made, but affects the training of the model instead. It should be noted that both this change and the previous one are pretty "hacky". The reason this isn't already possible in Darts is that I think we're in a pretty narrow use-case here--having some information from the future that extends past the prediction horizon. (NOTE: I also changed the `raise_if_not` call in `darts/utils/data/shifted_dataset.py` to check for equality with `input_chunk_length` instead of `output_chunk_length`).